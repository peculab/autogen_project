import os
import asyncio
import json
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.messages import TextMessage
from autogen_ext.models.openai import OpenAIChatCompletionClient
from dotenv import load_dotenv

load_dotenv()

async def process_user_diary(socketio, user_id, user_entries):
    model_client = OpenAIChatCompletionClient(
        model="gemini-2.0-flash",
        api_key=os.getenv("GEMINI_API_KEY"),
    )

    # åªå–å‰ 5 ç­†è³‡æ–™ï¼Œä¸¦å°‡ Timestamp è½‰ç‚ºå­—ä¸²é¿å… JSON åºåˆ—åŒ–å•é¡Œ
    records = user_entries.to_dict(orient='records')
    if len(records) > 5:
        prompt_records = json.dumps(records[:5], ensure_ascii=False, indent=2, default=str) + "\n... (ä»¥ä¸‹çœç•¥)"
    else:
        prompt_records = json.dumps(records, ensure_ascii=False, indent=2, default=str)
        
    # æ›´æ–° promptï¼Œè¦æ±‚ AI æ ¹æ“šæ—¥è¨˜ç”¢ç”Ÿå…¨æ–°çš„æ­£å‘å»ºè­°ï¼Œ
    # ä¸¦åœ¨å›è¦†æœ€å¾Œç›´æ¥è¼¸å‡ºæœ€çµ‚å»ºè­°ï¼Œæ ¼å¼å¿…é ˆä»¥ã€æœ€çµ‚å»ºè­°ï¼šã€é–‹é ­
    prompt = (
        f"ç›®å‰æ­£åœ¨è™•ç†ç”¨æˆ¶ {user_id} çš„æ—¥è¨˜ï¼Œå…± {len(user_entries)} å‰‡ã€‚\n"
        f"æ—¥è¨˜å…§å®¹ï¼ˆåƒ…é¡¯ç¤ºå‰ 5 ç­†ï¼‰ï¼š\n{prompt_records}\n\n"
        "è«‹ä»”ç´°åˆ†æä¸Šè¿°æ—¥è¨˜ï¼Œæ‰¾å‡ºç”¨æˆ¶çš„æƒ…ç·’èˆ‡æ€è€ƒæ¨¡å¼ï¼Œä¸¦æ ¹æ“šä½ çš„åˆ†æç”Ÿæˆä¸€æ®µå…¨æ–°çš„æ­£å‘å¿ƒæƒ…å»ºè­°ï¼Œå…§å®¹å¿…é ˆåŒ…å«ï¼š\n"
        "1. æƒ…ç·’èˆ‡æ€è€ƒæ¨¡å¼çš„è©³ç´°åˆ†æ\n"
        "2. å¯¦éš›å¯è¡Œçš„è¡Œå‹•æ–¹æ¡ˆå»ºè­°\n"
        "3. AI æ•™ç·´å¦‚ä½•æä¾›å€‹æ€§åŒ–äº’å‹•å»ºè­°\n\n"
        "è«‹æ³¨æ„ï¼šè«‹åƒ…ç”Ÿæˆå…¨æ–°å…§å®¹ï¼Œä¸è¦é‡è¤‡ä¸Šè¿°æç¤ºã€‚è«‹åœ¨å›è¦†æœ€å¾Œç›´æ¥è¼¸å‡ºæœ€çµ‚å»ºè­°ï¼Œæ ¼å¼å¿…é ˆä»¥ã€æœ€çµ‚å»ºè­°ï¼šã€é–‹é ­ï¼Œå¾Œé¢è·Ÿä¸Šä½ çš„å»ºè­°å…§å®¹ã€‚\n"
        "ä¾‹å¦‚ï¼š\n"
        "æœ€çµ‚å»ºè­°ï¼šæ ¹æ“šåˆ†æï¼Œå»ºè­°æ‚¨æ¯å¤©é€²è¡Œ10åˆ†é˜å†¥æƒ³ï¼Œä¸¦æ ¹æ“šå¿ƒæƒ…è¨˜éŒ„èª¿æ•´ä½œæ¯ï¼ŒåŒæ™‚èˆ‡ AI æ•™ç·´å®šæœŸè¨è«–æƒ…ç·’ç®¡ç†ç­–ç•¥ã€‚\n\n"
        "è«‹å‹™å¿…éµå®ˆä¸Šè¿°è¦æ±‚ã€‚"
    )

    # å»ºç«‹åˆæ³•çš„ agent åç¨±åŠé¡¯ç¤ºç”¨å°ç…§å­—å…¸
    analysis_agent = AssistantAgent("analysis_expert", model_client)
    coaching_agent = AssistantAgent("ai_coach", model_client)
    display_names = {
         "analysis_expert": "åˆ†æå°ˆå®¶",
         "ai_coach": "AI æ•™ç·´"
    }

    team = RoundRobinGroupChat([analysis_agent, coaching_agent])
    
    final_recommendation = None

    try:
        async for event in team.run_stream(task=prompt):
            if isinstance(event, TextMessage):
                display_name = display_names.get(event.source, event.source)
                message_text = f"ğŸ¤– [{display_name}]ï¼š{event.content}"
                # è‹¥è¨Šæ¯éé•·ï¼Œåƒ…æˆªå–å‰ 500 å€‹å­—é¡¯ç¤º
                if len(message_text) > 500:
                    message_text = message_text[:500] + " ... (å…§å®¹éé•·)"
                socketio.emit('update', {'message': message_text})
                
                # å¦‚æœè¨Šæ¯ä¸­åŒ…å«ã€Œæœ€çµ‚å»ºè­°ï¼šã€å‰‡å¾ä¸­æå–å»ºè­°å…§å®¹ä¸¦æ›´æ–°ã€å»ºè­°ã€‘å€å¡Š
                if "æœ€çµ‚å»ºè­°ï¼š" in event.content:
                    final_recommendation = event.content.split("æœ€çµ‚å»ºè­°ï¼š")[-1].strip()
                    socketio.emit('suggestions', {'suggestions': final_recommendation})
    except asyncio.exceptions.CancelledError:
        # è‹¥å› å–æ¶ˆæ“ä½œè€Œç™¼ç”Ÿ CancelledErrorï¼Œå¿½ç•¥å³å¯
        pass

async def run_multiagent_analysis(socketio, user_id, user_entries):
    await process_user_diary(socketio, user_id, user_entries)
